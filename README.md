# API Pipeline - E-commerce Data

Pipeline **ETL (Extract, Transform, Load)** desarrollado en Python que consume datos de una API de e-commerce, los transforma y los guarda en formato **Parquet**, tanto de forma consolidada como particionada por fecha.

Este proyecto fue realizado como parte del **Bootcamp de Data Engineering â€“ Ian Saura** y sigue buenas prÃ¡cticas profesionales: uso de variables de entorno, manejo de errores, logging y estructura modular.

---

## ğŸ“Œ DescripciÃ³n del Pipeline

El pipeline realiza los siguientes pasos:

1. **Extract**: Obtiene datos desde la API pÃºblica de Ian Saura utilizando autenticaciÃ³n mediante **email y API key**.
2. **Transform**: Limpia y transforma los datos usando pandas, agregando columnas derivadas y validaciones.
3. **Load**: Guarda los datos en formato Parquet:
   - Un archivo consolidado con todas las Ã³rdenes.
   - Datos particionados por aÃ±o y mes para optimizar consultas.

---

## ğŸ” AutenticaciÃ³n

La API utilizada requiere autenticaciÃ³n mediante dos parÃ¡metros:

- `email`
- `key` (API Key personal)

Estos valores se envÃ­an como parÃ¡metros en la request HTTP y se configuran mediante variables de entorno.

---

## âš™ï¸ Setup

### 1ï¸âƒ£ Clonar el repositorio

```bash
git clone <url-del-repositorio>
cd api-pipeline
```

---

### 2ï¸âƒ£ Crear el archivo .env

Crear un archivo .env en la raÃ­z del proyecto con el siguiente contenido:

```
EMAIL=tu_email_registrado
KEY=tu_api_key
API_BASE_URL=https://iansaura.com/api
```

âš ï¸ Importante: El archivo .env no debe subirse a GitHub. EstÃ¡ incluido en .gitignore.

---

### 3ï¸âƒ£ Instalar dependencias

```
pip install -r requirements.txt
```

---

### â–¶ï¸ Uso

Para ejecutar el pipeline completo:

```
python main.py
```

El pipeline incluye:

* Manejo de errores HTTP
* Logging detallado
* Reintentos automÃ¡ticos ante fallas de conexiÃ³n
* Transformaciones de datos con pandas

---

### ğŸ”„ Transformaciones aplicadas

Durante la etapa de transformaciÃ³n se realizan, entre otras, las siguientes operaciones:

* ConversiÃ³n de fechas (order_date)
* ConversiÃ³n de montos numÃ©ricos (total_amount)
* GeneraciÃ³n de nuevas columnas:
         * order_month
         * order_year
         * is_high_value
         * day_of_week

TambiÃ©n se validan valores invÃ¡lidos y se registran advertencias en los logs.

---

### ğŸ“‚ Output

Los datos generados se guardan en la carpeta output/:

output/
â”œâ”€â”€ orders/
â”‚   â””â”€â”€ order_year=2024/
â”‚       â”œâ”€â”€ order_month=2024-01/
â”‚       â”‚   â””â”€â”€ data.parquet
â”‚       â”œâ”€â”€ order_month=2024-02/
â”‚       â”‚   â””â”€â”€ data.parquet
â”‚       â””â”€â”€ ...
â””â”€â”€ orders_all.parquet

ğŸ“ Tipos de salida

* orders_all.parquet: archivo consolidado con todas las Ã³rdenes (Ãºtil para anÃ¡lisis exploratorio y debugging).

* orders/: datos particionados por aÃ±o y mes (pensado para consultas eficientes en producciÃ³n).

---

### ğŸ³ Docker

Este proyecto puede ejecutarse dentro de un container Docker para garantizar un entorno reproducible.

## Build de la imagen

Desde la raÃ­z del proyecto:

```
docker build -t api-pipeline .
```

## Ejecutar el container
```
docker run --env-file .env api-pipeline
```

---

### ğŸ› ï¸ TecnologÃ­as utilizadas

* Python 3
* requests
* pandas
* pyarrow
* python-dotenv

---

### ğŸ‘©â€ğŸ’» Autora

MarÃ­a Victoria D'Ercole